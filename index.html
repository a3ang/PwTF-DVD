<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Pixel-wise Temporal Frequency-based Deepfake Video Detection</title>
  <style>
    body {
      font-family: 'Segoe UI', 'Helvetica Neue', Arial, 'Liberation Sans', sans-serif;
      background: linear-gradient(135deg, #f0f4ff 0%, #f8fafc 100%);
      color: #232946;
      max-width: 950px;
      margin: 40px auto;
      padding: 0 20px 40px 20px;
    }
    header {
      position: relative;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      text-align: center;
      margin-bottom: 48px;
      padding: 56px 0 36px 0;
      background: linear-gradient(90deg, #e0e7ff 0%, #c7d2fe 100%);
      border-radius: 0 0 32px 32px;
      box-shadow: 0 4px 24px rgba(60,60,100,0.10);
      border-bottom: 2px solid #a5b4fc;
    }
    .iccv-badge {
      position: absolute;
      top: 24px;
      right: 36px;
      display: inline-flex;
      align-items: center;
      background: linear-gradient(90deg, #bae6fd 0%, #fef9c3 100%);
      color: #1e293b;
      font-size: 1.08rem;
      font-weight: 900;
      border-radius: 12px;
      padding: 6px 18px 6px 12px;
      box-shadow: 0 2px 10px #bae6fd80;
      gap: 7px;
      border: 1.5px solid #38bdf8;
      letter-spacing: 0.5px;
      font-family: 'Segoe UI', 'Arial Rounded MT Bold', Arial, sans-serif;
      text-shadow: 0 2px 8px #fff, 0 1px 0 #bae6fd;
      z-index: 2;
    }
    .iccv-badge svg {
      width: 1.5em;
      height: 1.5em;
      vertical-align: middle;
      margin-right: 2px;
      margin-left: 0;
    }
    .authors {
      color: #334155;
      font-size: 1.13rem;
      margin-bottom: 2px;
      text-align: center;
    }
    .affiliations {
      color: #64748b;
      font-size: 1.01rem;
      margin-bottom: 0;
      text-align: center;
    }
    .section {
      margin-bottom: 44px;
      background: linear-gradient(120deg, #f1f5f9 60%, #e0e7ff 100%);
      border-radius: 18px;
      box-shadow: 0 2px 12px rgba(60,60,100,0.07);
      padding: 36px 36px 26px 36px;
      border: 1.5px solid #e0e7ff;
    }
    h2 {
      color: #2563eb;
      font-size: 1.45rem;
      margin-bottom: 20px;
      font-weight: 700;
      letter-spacing: -0.5px;
      text-shadow: 0 2px 8px #e0e7ff80;
    }
    ul, ol {
      margin: 0 0 0 18px;
    }
    .fig-row {
      display: flex;
      flex-wrap: nowrap;
      gap: 32px;
      justify-content: space-between;
      align-items: stretch;
      margin: 28px 0 18px 0;
      width: 100%;
      max-width: 1200px;
      margin-left: auto;
      margin-right: auto;
    }
    .fig-card {
      flex: 1 1 0;
      max-width: 380px;
      height: auto;
      display: flex;
      flex-direction: column;
      align-items: center;
      background: linear-gradient(120deg, #f8fafc 60%, #e0e7ff 100%);
      border-radius: 14px;
      box-shadow: 0 1px 8px rgba(60,60,100,0.06);
      padding: 24px 16px 14px 16px;
      border: 1.2px solid #c7d2fe;
      transition: box-shadow 0.2s;
    }
    .fig-card.wide {
      flex: 2 1 0;
      max-width: 800px;
      height: auto;
      padding-left: 0;
      padding-right: 0;
    }
    .fig-card:hover {
      box-shadow: 0 6px 24px rgba(37,99,235,0.13);
    }
    .fig-card img {
      max-width: 100%;
      border-radius: 10px;
      margin-bottom: 12px;
      box-shadow: 0 2px 12px rgba(60,60,100,0.09);
      border: 1.2px solid #e0e7ff;
    }
    .fig-card.wide img {
      display: block;
      width: 600px;
      max-width: 95%;
      margin: 0 auto 12px auto;
      object-fit: contain;
      box-shadow: 0 4px 24px rgba(60,60,100,0.10);
      border-radius: 14px;
      border: 1.2px solid #e0e7ff;
    }
    @media (max-width: 1100px) {
      .fig-row { flex-wrap: wrap; }
      .fig-card, .fig-card.wide { max-width: 100%; min-width: 0; }
    }
    @media (max-width: 700px) {
      .fig-row { flex-direction: column; gap: 18px; }
      .iccv-badge {
        position: static;
        margin: 18px auto 0 auto;
        display: flex;
        justify-content: center;
      }
    }
    .fig-title {
      font-weight: 700;
      color: #334155;
      margin-bottom: 7px;
      font-size: 1.13em;
      text-align: center;
    }
    .fig-desc {
      color: #64748b;
      font-size: 1em;
      text-align: center;
      margin-bottom: 0;
    }
    #future-work {
      text-align: center;
      background: linear-gradient(90deg, #f0fdfa 0%, #e0e7ff 100%);
      color: #334155;
      font-size: 1.13rem;
      font-weight: 500;
      border: 2px dashed #a5b4fc;
      margin-top: 44px;
      border-radius: 14px;
      box-shadow: 0 2px 8px rgba(60,60,100,0.06);
      padding: 28px 0 18px 0;
    }
    .proj-btn {
      display: inline-flex;
      align-items: center;
      padding: 10px 22px 10px 14px;
      border-radius: 8px;
      background: #f1f5f9;
      color: #64748b;
      font-weight: 600;
      font-size: 1.08em;
      text-decoration: none;
      box-shadow: 0 2px 8px rgba(37,99,235,0.08);
      border: none;
      margin: 0;
      transition: background 0.18s, box-shadow 0.18s, transform 0.12s;
    }
    .proj-btn svg { margin-right: 7px; }
    .proj-btn:not(.disabled):hover {
      background: linear-gradient(90deg, #2563eb 0%, #38bdf8 100%);
      color: #fff;
      box-shadow: 0 4px 16px rgba(37,99,235,0.13);
      transform: translateY(-2px) scale(1.04);
    }
    .proj-btn.disabled {
      opacity: 0.6;
      cursor: not-allowed;
      pointer-events: none;
    }
    @media (max-width: 600px) {
      body { padding: 0 2vw; }
      .section { padding: 16px 4vw 10px 4vw; }
      header { padding: 24px 0 10px 0; }
      h1 { font-size: 1.3rem; }
    }
  </style>
</head>
<body>
  <header>
    <span class="iccv-badge">
      <svg viewBox="0 0 40 32" fill="none">
        <ellipse cx="32" cy="28" rx="6" ry="2.5" fill="#38bdf8"/>
        <ellipse cx="8" cy="28" rx="6" ry="2.5" fill="#38bdf8"/>
        <ellipse cx="20" cy="30" rx="16" ry="2" fill="#bae6fd"/>
        <circle cx="32" cy="10" r="5" fill="#fde047" stroke="#fbbf24" stroke-width="1.5"/>
        <path d="M8 28 Q10 18 20 18 Q30 18 32 28" stroke="#22c55e" stroke-width="2.2" fill="none"/>
        <path d="M20 18 Q22 13 28 13" stroke="#22c55e" stroke-width="1.5" fill="none"/>
        <path d="M20 18 Q18 13 12 13" stroke="#22c55e" stroke-width="1.5" fill="none"/>
        <path d="M28 13 Q29 11 32 11 Q35 11 36 13" stroke="#22c55e" stroke-width="1.1" fill="none"/>
        <path d="M12 13 Q11 11 8 11 Q5 11 4 13" stroke="#22c55e" stroke-width="1.1" fill="none"/>
        <path d="M32 10 Q33 7 36 7" stroke="#fbbf24" stroke-width="1.2" fill="none"/>
        <path d="M32 10 Q31 7 28 7" stroke="#fbbf24" stroke-width="1.2" fill="none"/>
      </svg>
      ICCV 2025
    </span>
    <h1>
      Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection
    </h1>
    <div class="authors">Taehoon Kim, Jongwook Choi, Yonghyun Jeong, Haeun Noh, Jaejun Yoo, Seungryul Baek, Jongwon Choi</div>
    <div class="affiliations">Chung-Ang Univ, NAVER Cloud, UNIST, Korea</div>
  </header>

  <div style="display:flex; justify-content:center; gap:18px; margin:32px 0 24px 0;">
    <a href="https://github.com/rama0126/PwTF-DVD" class="proj-btn" target="_blank" rel="noopener">
      <svg width="22" height="22" viewBox="0 0 24 24" fill="#333" style="vertical-align:middle; margin-right:7px;"><path d="M12 .5C5.73.5.5 5.73.5 12c0 5.08 3.29 9.39 7.86 10.91.58.11.79-.25.79-.56 0-.28-.01-1.02-.02-2-3.2.7-3.88-1.54-3.88-1.54-.53-1.34-1.3-1.7-1.3-1.7-1.06-.72.08-.71.08-.71 1.17.08 1.78 1.2 1.78 1.2 1.04 1.78 2.73 1.27 3.4.97.11-.75.41-1.27.74-1.56-2.56-.29-5.26-1.28-5.26-5.7 0-1.26.45-2.29 1.19-3.1-.12-.29-.52-1.46.11-3.05 0 0 .97-.31 3.18 1.18a11.1 11.1 0 0 1 2.9-.39c.98 0 1.97.13 2.9.39 2.2-1.49 3.17-1.18 3.17-1.18.63 1.59.23 2.76.11 3.05.74.81 1.19 1.84 1.19 3.1 0 4.43-2.7 5.41-5.27 5.7.42.36.79 1.09.79 2.2 0 1.59-.01 2.87-.01 3.26 0 .31.21.68.8.56C20.71 21.39 24 17.08 24 12c0-6.27-5.23-11.5-12-11.5z"/></svg>
      GitHub
    </a>
    <span class="proj-btn disabled">
      <svg width="22" height="22" viewBox="0 0 32 32" fill="#b31b1b" style="vertical-align:middle; margin-right:7px;"><rect width="32" height="32" rx="6"/><text x="16" y="22" text-anchor="middle" font-size="15" fill="#fff" font-family="Arial, sans-serif">arXiv</text></svg>
      arXiv
    </span>
    <span class="proj-btn disabled">
      <svg width="22" height="22" viewBox="0 0 24 24" fill="#2563eb" style="vertical-align:middle; margin-right:7px;"><path d="M6 2a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.83A2 2 0 0 0 19.41 7L15 2.59A2 2 0 0 0 13.17 2H6zm7 1.5L18.5 9H15a2 2 0 0 1-2-2V3.5z"/></svg>
      ICCV Paper
    </span>
    <span class="proj-btn disabled">
      <svg width="22" height="22" viewBox="0 0 32 32" style="vertical-align:middle; margin-right:7px;"><circle cx="16" cy="16" r="16" fill="#FFD21F"/><ellipse cx="11" cy="13.5" rx="2" ry="2.5" fill="#fff"/><ellipse cx="21" cy="13.5" rx="2" ry="2.5" fill="#fff"/><ellipse cx="11" cy="14" rx="1" ry="1.5" fill="#333"/><ellipse cx="21" cy="14" rx="1" ry="1.5" fill="#333"/><path d="M10 20c1.5 2 6.5 2 8 0" stroke="#333" stroke-width="1.5" stroke-linecap="round" fill="none"/></svg>
      Hugging Face Demo
    </span>
  </div>




  <section class="section" id="abstract">
    <h2>Abstract</h2>
    <p>
      We introduce a novel method for deepfake video detection that utilizes <b>pixel-wise temporal frequency spectra</b>. Unlike previous approaches that stack 2D frame-wise spatial frequency spectra, we extract pixel-wise temporal frequency by performing a 1D Fourier transform on the time axis per pixel, effectively identifying temporal artifacts. We also propose an <b>Attention Proposal Module (APM)</b> to extract regions of interest for detecting these artifacts. Our method demonstrates outstanding generalizability and robustness in various challenging deepfake video detection scenarios.
    </p>
  </section>
  <section class="section" id="method">
    <h2>Method & Architecture</h2>
    <div class="fig-row">
      <div class="fig-card">
        <div class="fig-title">Frequency Extraction</div>
        <img src="figures/figure2.png" alt="Temporal artifacts and frequency extraction method">
        <div class="fig-desc">Our method captures subtle temporal artifacts in deepfake videos by applying a 1D Fourier transform to each pixel over time, unlike previous methods that rely on spatial frequency stacking.</div>
      </div>
      <div class="fig-card wide">
        <div class="fig-title">Proposed Architecture</div>
        <img src="figures/figure3.png" alt="Frequency Feature Extractor and Joint Transformer Module">
        <div class="fig-desc">The pipeline consists of a Frequency Feature Extractor (with pixel-wise temporal Fourier transform and Attention Proposal Module) and a Joint Transformer Module for robust deepfake detection.</div>
      </div>
    </div>
    <!-- <div style="background:#e0e7ff; border-left:4px solid #2563eb; border-radius:10px; margin:18px 0 24px 0; padding:18px 18px 12px 18px; font-size:1.05em; color:#222;">
      <b>Proposed Architecture (Mathematical Description):</b><br>
      <span style="font-size:0.98em; color:#334155;">
        For extracting temporal frequency <span style="font-family:serif;">F<sup>0</sup></span>, the video clip <span style="font-family:serif;">V</span> is decomposed into temporal frequency components using the Fourier Transform.<br>
        The frequency feature extractor obtains a part-based frequency feature <span style="font-family:serif;">Z<sup>p</sup></span> and a global frequency feature <span style="font-family:serif;">Z<sup>0</sup></span> using 2D ResNet and an attention proposal module.<br>
        The part-based and global frequency features enter the feature blender to get a blended feature <span style="font-family:serif;">Z<sup>+</sup></span>, and put the blended features, part-based frequency features, and global frequency features into a joint transformer module to classify real and fake.
      </span>
    </div> -->
    
    <ul>
      <li><b>Pixel-wise Temporal Frequency Extraction:</b> 1D Fourier transform along the time axis for each pixel, capturing subtle temporal artifacts.</li>
      <li><b>Attention Proposal Module (APM):</b> Learns to focus on regions with temporal artifacts using weak supervision.</li>
      <li><b>Joint Transformer Module:</b> Fuses global/part-based frequency features and spatio-temporal context for final classification.</li>
    </ul>
  </section>

  <section class="section" id="experiments">
    <h2>Experiments & Results</h2>
    <div class="fig-row">
      <div class="fig-card">
        <div class="fig-title">Attention Proposal Module (APM) Visualization</div>
        <img src="figures/figure5.png" alt="Visualization of APM proposed regions over time">
        <div class="fig-desc">The APM automatically focuses on regions (e.g., eyes, mouth) where temporal incoherence is most likely, enabling more precise detection of deepfake artifacts.</div>
      </div>
      <div class="fig-card">
        <div class="fig-title">Performance Comparison</div>
        <img src="figures/figure1.png" alt="Video-level AUC and method comparison">
        <div class="fig-desc">Our method achieves state-of-the-art video-level AUC across multiple datasets, demonstrating superior generalization and robustness compared to previous approaches.</div>
      </div>
    </div>
    <ul>
      <li>Achieves <b>state-of-the-art</b> performance on multiple datasets (FF++, CDF, DFDC, KoDF, etc.).</li>
      <li>Demonstrates strong <b>generalization</b> in cross-deepfakes and cross-synthesis experiments.</li>
      <li><b>APM</b> is effective in identifying regions of interest for deepfake detection.</li>
    </ul>
  </section>
  <section class="section" id="contributions">
    <h2>Key Contributions</h2>
    <ul>
      <li>Introduces <b>pixel-wise temporal frequency</b> for deepfake video detection.</li>
      <li>Utilizes an <b>Attention Proposal Module (APM)</b> to identify regions of interest.</li>
      <li>Leverages a <b>joint transformer module</b> to leverage temporal-frequency information.</li>
      <li>Achieves <b>state-of-the-art performance</b> and generalizability.</li>
    </ul>
  </section>
  <!-- <section class="section" id="conclusion">
    <h2>Conclusion</h2>
    <p style="text-align: center;">
      We present a novel forgery detection approach based on pixel-wise temporal frequency. We first demonstrate that temporal frequency can be used to detect forgery and then use experiments to show how it can help where other methods fail. Contrary to spatial frequency, pixel-wise temporal frequency can detect local temporal inconsistency, which makes generalized deepfake video detection possible. We also propose a framework to fuse temporal frequency information with RGB video information. Finally, we perform forgery detection through the automatic mechanism of extracting the region of interest and our solution is more robust and generalized than previous methods.
    </p>
  </section> -->
  <section id="limitations-future-work" class="section">
    <h2>Limitations & Future Work</h2>
  
    <div style="
        background: linear-gradient(90deg, #fef9c3 0%, #e0e7ff 100%);
        border-left: 5px solid #f59e42;
        border-radius: 12px;
        padding: 20px 22px;
        margin-bottom: 16px;
        font-size: 1.08em;
      ">
      <strong style="color:#b45309; font-weight:700;">Highlight:</strong>
      <ul style="margin: 12px 0 0 20px; padding: 0; list-style-type: disc;">

        <li>
          <span style="color:#e11d48; font-weight:600;">Heavy compression</span> (H.264, JPEG, WebP)
          merges neighboring pixels and diminishes pixel-level motion, inducing domain shifts in the temporal frequency.
        </li>
        <li>
          Compressed videos match the raw signal closely at
          <span style="color:#7c3aed; font-weight:600;">low frequencies</span>,
          but diverge significantly in the
          <span style="color:#f43f5e; font-weight:600;">high-frequency</span> range.
        </li>
      </ul>
    </div>
  
    <p>
      We measured the average pixel-wise temporal frequency under various
      compression schemes (H.264, JPEG, WebP). At low frequencies, compressed
      footage aligns closely with the uncompressed baseline; at high frequencies,
      spectrum attenuation explains the observed performance drop under severe
      compression.
    </p>
  
    <div style="
        background: linear-gradient(90deg, #fef9c3 0%, #e0e7ff 100%);
        border-left: 5px solid #f59e42;
        border-radius: 12px;
        padding: 20px 22px;
        margin-bottom: 16px;
        font-size: 1.08em;
      ">
      <strong style="color:#b45309; font-weight:700;">Future Work:</strong>
      <p style="margin: 12px 0 0 0;">
        This sensitivity to heavy compression remains a limitation. In future work,
        we will investigate <span style="color:#e11d48; font-weight:600;">temporal-frequency regularization techniques</span> to
        mitigate performance degradation.
      </p>
    </div>
  </section>
  
  

  <section id="future-work">
    <h2>Coming Soon</h2>
    <p>Code, Demo and paper will be released soon.<br>Stay tuned for updates!</p>
  </section>
</body>
</html>

</html>
